{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T17:00:38.727567Z",
     "iopub.status.busy": "2021-10-26T17:00:38.727285Z",
     "iopub.status.idle": "2021-10-26T17:00:38.730682Z",
     "shell.execute_reply": "2021-10-26T17:00:38.730051Z",
     "shell.execute_reply.started": "2021-10-26T17:00:38.727541Z"
    }
   },
   "source": [
    "# arXiv Paper Embedding\n",
    "\n",
    "## On a Single GPU\n",
    "This notebook utilizes an NVIDIA T4 on Saturn Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:23:56.449180Z",
     "iopub.status.busy": "2022-09-21T13:23:56.448777Z",
     "iopub.status.idle": "2022-09-21T13:23:56.452622Z",
     "shell.execute_reply": "2022-09-21T13:23:56.452121Z",
     "shell.execute_reply.started": "2022-09-21T13:23:56.449152Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "\n",
    "DATA_PATH = \"arxiv-metadata-oai-snapshot.json\"\n",
    "YEAR_PATTERN = r\"(19|20[0-9]{2})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data pre processing\n",
    "Before we do anything else, we need to load the papers dataset, do some basic cleaning, and get it into a workable format. Below,\n",
    "we will use CuDF to house the data and apply seom transformations in a generator, loading from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:23:57.897125Z",
     "iopub.status.busy": "2022-09-21T13:23:57.896729Z",
     "iopub.status.idle": "2022-09-21T13:23:57.901878Z",
     "shell.execute_reply": "2022-09-21T13:23:57.901359Z",
     "shell.execute_reply.started": "2022-09-21T13:23:57.897098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_description(description: str):\n",
    "    if not description:\n",
    "        return \"\"\n",
    "    # remove unicode characters\n",
    "    description = description.encode('ascii', 'ignore').decode()\n",
    "\n",
    "    # remove punctuation\n",
    "    description = re.sub('[%s]' % re.escape(string.punctuation), ' ', description)\n",
    "\n",
    "    # clean up the spacing\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # remove urls\n",
    "    #description = re.sub(\"https*\\S+\", \" \", description)\n",
    "\n",
    "    # remove newlines\n",
    "    description = description.replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove all numbers\n",
    "    #description = re.sub('\\w*\\d+\\w*', '', description)\n",
    "\n",
    "    # split on capitalized words\n",
    "    description = \" \".join(re.split('(?=[A-Z])', description))\n",
    "\n",
    "    # clean up the spacing again\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # make all words lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:24:01.262270Z",
     "iopub.status.busy": "2022-09-21T13:24:01.261887Z",
     "iopub.status.idle": "2022-09-21T13:24:01.268210Z",
     "shell.execute_reply": "2022-09-21T13:24:01.267674Z",
     "shell.execute_reply.started": "2022-09-21T13:24:01.262244Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator functions that iterate through the file and process/load papers\n",
    "\n",
    "def process(paper: dict):\n",
    "    paper = json.loads(paper)\n",
    "    if paper['journal-ref']:\n",
    "        # Attempt to parse the date using Regex: this could be improved\n",
    "        years = [int(year) for year in re.findall(YEAR_PATTERN, paper['journal-ref'])]\n",
    "        years = [year for year in years if (year <= 2022 and year >= 1991)]\n",
    "        year = min(years) if years else None\n",
    "    else:\n",
    "        year = None\n",
    "    return {\n",
    "        'id': paper['id'],\n",
    "        'title': paper['title'],\n",
    "        'year': year,\n",
    "        'authors': paper['authors'],\n",
    "        'categories': ','.join(paper['categories'].split(' ')),\n",
    "        'abstract': paper['abstract'],\n",
    "        'input': clean_description(paper['title'] + ' ' + paper['abstract']) # embedding model input\n",
    "    }\n",
    "\n",
    "def papers():\n",
    "    with open(DATA_PATH, 'r') as f:\n",
    "        for paper in f:\n",
    "            paper = process(paper)\n",
    "            # Yield only papers that have a year I could process\n",
    "            if paper['year']:\n",
    "                yield paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:24:02.622359Z",
     "iopub.status.busy": "2022-09-21T13:24:02.621970Z",
     "iopub.status.idle": "2022-09-21T13:24:02.628013Z",
     "shell.execute_reply": "2022-09-21T13:24:02.627526Z",
     "shell.execute_reply.started": "2022-09-21T13:24:02.622332Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0001',\n",
       " 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       " 'year': 2007,\n",
       " 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       " 'categories': 'hep-ph',\n",
       " 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       " 'input': ' calculation of prompt diphoton production cross sections at tevatron and l h c energies a fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders all next to leading order perturbative contributions from quark antiquark gluon anti quark and gluon gluon subprocesses are included as well as all orders resummation of initial state gluon radiation valid at next to next to leading logarithmic accuracy the region of phase space is specified in which the calculation is most reliable good agreement is demonstrated with data from the fermilab tevatron and predictions are made for more detailed tests with c d f and d o data predictions are shown for distributions of diphoton pairs produced at the energy of the large hadron collider l h c distributions of the diphoton pairs from the decay of a higgs boson are contrasted with those produced from q c d processes at the l h c showing that enhanced sensitivity to the signal can be obtained with judicious selection of events '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "next(papers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T19:52:16.927835Z",
     "iopub.status.busy": "2022-09-20T19:52:16.927445Z",
     "iopub.status.idle": "2022-09-20T19:56:12.396656Z",
     "shell.execute_reply": "2022-09-20T19:56:12.396067Z",
     "shell.execute_reply.started": "2022-09-20T19:52:16.927809Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load papers into a CuDF\n",
    "cdf = cudf.DataFrame(list(papers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T19:56:12.398820Z",
     "iopub.status.busy": "2022-09-20T19:56:12.398468Z",
     "iopub.status.idle": "2022-09-20T19:56:12.402540Z",
     "shell.execute_reply": "2022-09-20T19:56:12.402022Z",
     "shell.execute_reply.started": "2022-09-20T19:56:12.398795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T19:59:54.533059Z",
     "iopub.status.busy": "2022-09-20T19:59:54.532672Z",
     "iopub.status.idle": "2022-09-20T19:59:54.548644Z",
     "shell.execute_reply": "2022-09-20T19:59:54.548169Z",
     "shell.execute_reply.started": "2022-09-20T19:59:54.533033Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    46511\n",
       "2019    44098\n",
       "2021    43344\n",
       "2018    41643\n",
       "2017    38960\n",
       "2016    37540\n",
       "2015    35015\n",
       "2014    33854\n",
       "2010    32318\n",
       "2009    31998\n",
       "2013    31486\n",
       "2011    31048\n",
       "2012    30105\n",
       "2007    28917\n",
       "2006    28582\n",
       "2008    28511\n",
       "2005    26305\n",
       "2004    24418\n",
       "2003    22475\n",
       "2022    20996\n",
       "2002    20498\n",
       "2001    18826\n",
       "2000    15913\n",
       "Name: year, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T03:36:34.439386Z",
     "iopub.status.busy": "2022-09-21T03:36:34.439001Z",
     "iopub.status.idle": "2022-09-21T03:36:37.907965Z",
     "shell.execute_reply": "2022-09-21T03:36:37.907367Z",
     "shell.execute_reply.started": "2022-09-21T03:36:34.439358Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pickle the dataframe to save you time in the future\n",
    "\n",
    "with open('cdf.pkl', 'wb') as f:\n",
    "    pickle.dump(cdf, f)\n",
    "    \n",
    "# Load pickle\n",
    "# with open('cdf.pkl', 'rb') as f:\n",
    "#     cdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create sentence embeddings\n",
    "Here I use a cookie-cutter -- **out of the box** -- model from HuggingFace to transform papers abstracts + titles into vectors.\n",
    "\n",
    "**This takes a long time**... So best to take a subset. Or use the dask cluster for multi-gpu encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = cdf[:100000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T03:36:46.543244Z",
     "iopub.status.busy": "2022-09-21T03:36:46.542837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec9068c34a349c5bcb0e0ca21ee2e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "vectors = model.encode(\n",
    "    sentences = batch.input.values_host,\n",
    "    normalize_embeddings = True,\n",
    "    batch_size = 64,\n",
    "    show_progress_bar = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectors created!\n",
    "batch['vector'] = cudf.Series(vectors.tolist(), index=batch.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dump these to file with pickle or write them to Redis\n",
    "with open('embeddings_100000.pkl', 'wb') as f:\n",
    "    pickle.dump(batch, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
