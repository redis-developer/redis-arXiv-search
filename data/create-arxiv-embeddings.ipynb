{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e23fb70",
   "metadata": {},
   "source": [
    "# Create arXiv Embeddings\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1) Pull the arXiv dataset from Kaggle\n",
    "2) Perform data preprocessing and cleanup\n",
    "3) Create HuggingFace embeddings\n",
    "4) Create OpenAI embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a25dbc0",
   "metadata": {},
   "source": [
    "## 1 - Pull the arXiv dataset from Kaggle\n",
    "You will need to get a free API key from kaggle.com in order to [download this dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv). You can also manually download it as long as the `.json` file ends up in this directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340c00bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (1.5.12)\n",
      "Requirement already satisfied: tqdm in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: certifi in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.10 in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (2.28.2)\n",
      "Requirement already satisfied: python-slugify in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tyler.hutcherson/miniconda3/envs/openai-qna-env/lib/python3.10/site-packages (from requests->kaggle) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92d9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ad1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d Cornell-University/arxiv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e0295ed",
   "metadata": {},
   "source": [
    "Unzip the file and there you have it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93fa47f7",
   "metadata": {},
   "source": [
    "## 2 - Perform data preprocessing and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc20c14a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/yvsygb190g762bm8x582x3dh0000gp/T/ipykernel_57480/4146095499.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "DATA_PATH = \"arxiv-metadata-oai-snapshot.json\"\n",
    "YEAR_CUTOFF = 2012\n",
    "YEAR_PATTERN = r\"(19|20[0-9]{2})\"\n",
    "ML_CATEGORY = \"cs.LG\"\n",
    "DATASET_SIZE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e20498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing function to clean data\n",
    "def process(paper: dict):\n",
    "    paper = json.loads(paper)\n",
    "    if paper['journal-ref']:\n",
    "        years = [int(year) for year in re.findall(YEAR_PATTERN, paper['journal-ref'])]\n",
    "        years = [year for year in years if (year <= 2022 and year >= 1991)]\n",
    "        year = min(years) if years else None\n",
    "    else:\n",
    "        year = None\n",
    "    return {\n",
    "        'id': paper['id'],\n",
    "        'title': paper['title'],\n",
    "        'year': year,\n",
    "        'authors': paper['authors'],\n",
    "        'categories': ','.join(paper['categories'].split(' ')),\n",
    "        'abstract': paper['abstract']\n",
    "    }\n",
    "\n",
    "# Data loading function\n",
    "def papers():\n",
    "    with open(DATA_PATH, 'r') as f:\n",
    "        for paper in f:\n",
    "            paper = process(paper)\n",
    "            if paper['year']:\n",
    "                if paper['year'] >= YEAR_CUTOFF and ML_CATEGORY in paper['categories']:\n",
    "                    yield paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04abead5-2567-47ed-ac51-abb10ca4b4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset into Pandas dataframe and take a sample\n",
    "df = pd.DataFrame(papers()).sample(n=DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee130cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.084"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg length of the abstracts - num tokens\n",
    "df.abstract.apply(lambda a: len(a.split())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1415eabf-965a-465a-98ec-7cdec531f933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to clean the description!\n",
    "def clean_description(description: str):\n",
    "    if not description:\n",
    "        return \"\"\n",
    "    # remove unicode characters\n",
    "    description = description.encode('ascii', 'ignore').decode()\n",
    "\n",
    "    # remove punctuation\n",
    "    description = re.sub('[%s]' % re.escape(string.punctuation), ' ', description)\n",
    "\n",
    "    # clean up the spacing\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # remove urls\n",
    "    #description = re.sub(\"https*\\S+\", \" \", description)\n",
    "\n",
    "    # remove newlines\n",
    "    description = description.replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove all numbers\n",
    "    #description = re.sub('\\w*\\d+\\w*', '', description)\n",
    "\n",
    "    # split on capitalized words\n",
    "    description = \" \".join(re.split('(?=[A-Z])', description))\n",
    "\n",
    "    # clean up the spacing again\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # make all words lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    return description.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad625b2-c624-4dc6-bf42-d2f671f760c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the cleaner method on both title and abstract\n",
    "texts = df.apply(lambda r: clean_description(r['title'] + ' ' + r['abstract']), axis=1).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1204072-fcf3-4fca-bf09-b7db67067cb8",
   "metadata": {},
   "source": [
    "## 3 - Creating Hugging Face Embeddings\n",
    "\n",
    "First up, we will use the built-in RedisVL vectorizer to create embeddings from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef747be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "\n",
    "hf = HFTextVectorizer(model=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249ad360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embeddings from the title and abstract\n",
    "embeddings = hf.embed_many(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be859336-06dc-46ff-9452-716604105f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005483315791934729,\n",
       " 0.06285043805837631,\n",
       " -0.04415518790483475,\n",
       " -0.07510741800069809,\n",
       " -0.020236646756529808,\n",
       " 0.03126000240445137,\n",
       " 0.03337767347693443,\n",
       " 0.03219094127416611,\n",
       " -0.023321175947785378,\n",
       " 0.02857762947678566]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b4974a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add embeddings to df\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "df['huggingface'] = embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34787921-62ec-4279-ab9b-fcd9290f6b2f",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings\n",
    "\n",
    "Next, we will use OpenAI Embeddings for our arXiv papers. You will need to set your OpenAI API Key below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff3304a9-a492-4a9d-9d90-ebd66a89968c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import OpenAITextVectorizer\n",
    "\n",
    "oai = OpenAITextVectorizer(api_config={\"api_key\": \"YOUR API KEY HERE\"})\n",
    "\n",
    "embeddings = await oai.aembed_many(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1de9f18-8dd0-43c4-9e94-436f0751389e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c84a46-d118-4f99-adc5-c1b524c9fe7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034895237535238266,\n",
       " 0.0013622459955513477,\n",
       " 0.025790950283408165,\n",
       " -0.031307876110076904,\n",
       " -0.0186705831438303,\n",
       " 0.027937931939959526,\n",
       " 0.008866488933563232,\n",
       " 0.01263049989938736,\n",
       " -0.03155247122049332,\n",
       " -0.022502535954117775]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c25023d9-29b4-49f0-b2f6-d26ba18c4461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['openai'] = embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa668f02",
   "metadata": {},
   "source": [
    "## Cohere Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb328965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import CohereTextVectorizer\n",
    "\n",
    "co = CohereTextVectorizer(\n",
    "    model=\"embed-multilingual-v3.0\",\n",
    "    api_config={\"api_key\": \"YOUR API KEY HERE\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f48d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = co.embed_many(texts, input_type=\"search_document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a290ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb5588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d00656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cohere'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf0e5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>huggingface</th>\n",
       "      <th>openai</th>\n",
       "      <th>cohere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1812.02855</td>\n",
       "      <td>Progressive Sampling-Based Bayesian Optimizati...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xueqiang Zeng, Gang Luo</td>\n",
       "      <td>cs.LG,stat.ML</td>\n",
       "      <td>Purpose: Machine learning is broadly used fo...</td>\n",
       "      <td>[0.005483315791934729, 0.06285043805837631, -0...</td>\n",
       "      <td>[-0.034895237535238266, 0.0013622459955513477,...</td>\n",
       "      <td>[-0.0146865845, -0.023620605, 0.009109497, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1708.01422</td>\n",
       "      <td>Exploring the Function Space of Deep-Learning ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bo Li and David Saad</td>\n",
       "      <td>cond-mat.dis-nn,cs.LG</td>\n",
       "      <td>The function space of deep-learning machines...</td>\n",
       "      <td>[-0.022667571902275085, 0.04551266133785248, -...</td>\n",
       "      <td>[-0.017496585845947266, -0.009123609401285648,...</td>\n",
       "      <td>[0.020828247, -0.004623413, -0.009017944, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.00561</td>\n",
       "      <td>PrivacyNet: Semi-Adversarial Networks for Mult...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Vahid Mirjalili, Sebastian Raschka, Arun Ross</td>\n",
       "      <td>cs.CV,cs.CR,cs.LG</td>\n",
       "      <td>Recent research has established the possibil...</td>\n",
       "      <td>[-0.004289142321795225, 0.1055050864815712, -0...</td>\n",
       "      <td>[-0.0183021891862154, 0.004181693773716688, 0....</td>\n",
       "      <td>[0.024093628, 0.0047302246, -0.032104492, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003.01300</td>\n",
       "      <td>Few-Shot Relation Learning with Attention for ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sion An, Soopil Kim, Philip Chikontwe and Sang...</td>\n",
       "      <td>eess.SP,cs.LG</td>\n",
       "      <td>Brain-Computer Interfaces (BCI) based on Ele...</td>\n",
       "      <td>[-0.033013615757226944, 0.05156606808304787, -...</td>\n",
       "      <td>[-0.036494333297014236, 0.003500517923384905, ...</td>\n",
       "      <td>[-0.045196533, -0.009727478, 0.016662598, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902.03896</td>\n",
       "      <td>Reconstructing dynamical networks via feature ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Marc G. Leguia and Zoran Levnajic and Ljupco T...</td>\n",
       "      <td>math.DS,cs.LG,cs.SI,physics.soc-ph,stat.ML</td>\n",
       "      <td>Empirical data on real complex systems are b...</td>\n",
       "      <td>[-0.07013913244009018, 0.05345052108168602, -0...</td>\n",
       "      <td>[-0.017974110320210457, 0.010659225285053253, ...</td>\n",
       "      <td>[0.05041504, 0.03857422, -0.00983429, 0.029983...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  year  \\\n",
       "0  1812.02855  Progressive Sampling-Based Bayesian Optimizati...  2017   \n",
       "1  1708.01422  Exploring the Function Space of Deep-Learning ...  2018   \n",
       "2  2001.00561  PrivacyNet: Semi-Adversarial Networks for Mult...  2020   \n",
       "3  2003.01300  Few-Shot Relation Learning with Attention for ...  2020   \n",
       "4  1902.03896  Reconstructing dynamical networks via feature ...  2019   \n",
       "\n",
       "                                             authors  \\\n",
       "0                            Xueqiang Zeng, Gang Luo   \n",
       "1                               Bo Li and David Saad   \n",
       "2      Vahid Mirjalili, Sebastian Raschka, Arun Ross   \n",
       "3  Sion An, Soopil Kim, Philip Chikontwe and Sang...   \n",
       "4  Marc G. Leguia and Zoran Levnajic and Ljupco T...   \n",
       "\n",
       "                                   categories  \\\n",
       "0                               cs.LG,stat.ML   \n",
       "1                       cond-mat.dis-nn,cs.LG   \n",
       "2                           cs.CV,cs.CR,cs.LG   \n",
       "3                               eess.SP,cs.LG   \n",
       "4  math.DS,cs.LG,cs.SI,physics.soc-ph,stat.ML   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    Purpose: Machine learning is broadly used fo...   \n",
       "1    The function space of deep-learning machines...   \n",
       "2    Recent research has established the possibil...   \n",
       "3    Brain-Computer Interfaces (BCI) based on Ele...   \n",
       "4    Empirical data on real complex systems are b...   \n",
       "\n",
       "                                         huggingface  \\\n",
       "0  [0.005483315791934729, 0.06285043805837631, -0...   \n",
       "1  [-0.022667571902275085, 0.04551266133785248, -...   \n",
       "2  [-0.004289142321795225, 0.1055050864815712, -0...   \n",
       "3  [-0.033013615757226944, 0.05156606808304787, -...   \n",
       "4  [-0.07013913244009018, 0.05345052108168602, -0...   \n",
       "\n",
       "                                              openai  \\\n",
       "0  [-0.034895237535238266, 0.0013622459955513477,...   \n",
       "1  [-0.017496585845947266, -0.009123609401285648,...   \n",
       "2  [-0.0183021891862154, 0.004181693773716688, 0....   \n",
       "3  [-0.036494333297014236, 0.003500517923384905, ...   \n",
       "4  [-0.017974110320210457, 0.010659225285053253, ...   \n",
       "\n",
       "                                              cohere  \n",
       "0  [-0.0146865845, -0.023620605, 0.009109497, 0.0...  \n",
       "1  [0.020828247, -0.004623413, -0.009017944, 0.06...  \n",
       "2  [0.024093628, 0.0047302246, -0.032104492, 0.04...  \n",
       "3  [-0.045196533, -0.009727478, 0.016662598, 0.00...  \n",
       "4  [0.05041504, 0.03857422, -0.00983429, 0.029983...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d149609",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6037246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Write to file\n",
    "\n",
    "with open(\"arxiv-papers-1000.json\", \"w\") as f:\n",
    "    json.dump(d, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1101703b484e21b4c7da4bb676c119e6751760496c5c0670e93208ab08ae0e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
