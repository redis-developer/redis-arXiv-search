{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T17:00:38.727567Z",
     "iopub.status.busy": "2021-10-26T17:00:38.727285Z",
     "iopub.status.idle": "2021-10-26T17:00:38.730682Z",
     "shell.execute_reply": "2021-10-26T17:00:38.730051Z",
     "shell.execute_reply.started": "2021-10-26T17:00:38.727541Z"
    }
   },
   "source": [
    "# arXiv Paper Embedding\n",
    "\n",
    "\n",
    "## Multi GPU w/ Dask + CUDF\n",
    "Using Dask and CuDF to orchestrate sentence embedding over multiple GPU workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rapids and Dask Logos](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/rapids_dask.png \"doc-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Imports\n",
    "\n",
    "* [`dask_saturn`](https://github.com/saturncloud/dask-saturn) and [`dask_distributed`](http://distributed.dask.org/en/stable/): Set up and run the Dask cluster in Saturn Cloud.\n",
    "* [`dask-cudf`](https://docs.rapids.ai/api/cudf/stable/basics/dask-cudf.html): Create distributed `cudf` dataframes using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:13:10.115949Z",
     "iopub.status.busy": "2022-09-21T14:13:10.115512Z",
     "iopub.status.idle": "2022-09-21T14:13:11.261003Z",
     "shell.execute_reply": "2022-09-21T14:13:11.260461Z",
     "shell.execute_reply.started": "2022-09-21T14:13:10.115875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask_cudf\n",
    "import cudf\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client, wait\n",
    "\n",
    "\n",
    "DATA_PATH = \"arxiv-metadata-oai-snapshot.json\"\n",
    "YEAR_CUTOFF = 2022\n",
    "YEAR_PATTERN = r\"(19|20[0-9]{2})\"\n",
    "ML_CATEGORY = \"cs.LG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Dask Cluster\n",
    "\n",
    "The template resource you are running has a Dask cluster already attached to it with three workers. The `dask-saturn` code below creates two important objects: a cluster and a client.\n",
    "\n",
    "* `cluster`: knows about and manages the scheduler and workers\n",
    "    - can be used to create, resize, reconfigure, or destroy those resources\n",
    "    - knows how to communicate with the scheduler, and where to find logs and diagnostic dashboards\n",
    "* `client`: tells the cluster to do things\n",
    "    - can send work to the cluster\n",
    "    - can restart all the worker processes\n",
    "    - can send data to the cluster or pull data back from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:13:11.788520Z",
     "iopub.status.busy": "2022-09-21T14:13:11.787958Z",
     "iopub.status.idle": "2022-09-21T14:13:12.176508Z",
     "shell.execute_reply": "2022-09-21T14:13:12.175972Z",
     "shell.execute_reply.started": "2022-09-21T14:13:11.788490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:Success!\n"
     ]
    }
   ],
   "source": [
    "n_workers = 4\n",
    "cluster = SaturnCluster(n_workers=n_workers)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already started the Dask cluster on the resource page, then the code above will run much more quickly since it will not have to wait for the cluster to turn on.\n",
    "\n",
    ">**Pro tip**: Create and start the cluster in the Saturn Cloud UI before opening JupyterLab if you want to get a head start!\n",
    "\n",
    "The last command ensures the kernel waits until all the desired workers are online before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:13:14.091024Z",
     "iopub.status.busy": "2022-09-21T14:13:14.090611Z",
     "iopub.status.idle": "2022-09-21T14:15:05.646887Z",
     "shell.execute_reply": "2022-09-21T14:15:05.646302Z",
     "shell.execute_reply.started": "2022-09-21T14:13:14.090998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_description(description: str):\n",
    "    if not description:\n",
    "        return \"\"\n",
    "    # remove unicode characters\n",
    "    description = description.encode('ascii', 'ignore').decode()\n",
    "\n",
    "    # remove punctuation\n",
    "    description = re.sub('[%s]' % re.escape(string.punctuation), ' ', description)\n",
    "\n",
    "    # clean up the spacing\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # remove urls\n",
    "    #description = re.sub(\"https*\\S+\", \" \", description)\n",
    "\n",
    "    # remove newlines\n",
    "    description = description.replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove all numbers\n",
    "    #description = re.sub('\\w*\\d+\\w*', '', description)\n",
    "\n",
    "    # split on capitalized words\n",
    "    description = \" \".join(re.split('(?=[A-Z])', description))\n",
    "\n",
    "    # clean up the spacing again\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # make all words lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process(paper: dict):\n",
    "    paper = json.loads(paper)\n",
    "    if paper['journal-ref']:\n",
    "        years = [int(year) for year in re.findall(YEAR_PATTERN, paper['journal-ref'])]\n",
    "        years = [year for year in years if (year <= 2022 and year >= 1991)]\n",
    "        year = min(years) if years else None\n",
    "    else:\n",
    "        year = None\n",
    "    return {\n",
    "        'id': paper['id'],\n",
    "        'title': paper['title'],\n",
    "        'year': year,\n",
    "        'authors': paper['authors'],\n",
    "        'categories': ','.join(paper['categories'].split(' ')),\n",
    "        'abstract': paper['abstract'],\n",
    "        'input': clean_description(paper['title'] + ' ' + paper['abstract'])\n",
    "    }\n",
    "\n",
    "def papers():\n",
    "    with open(DATA_PATH, 'r') as f:\n",
    "        for paper in f:\n",
    "            paper = process(paper)\n",
    "            if paper['year']:\n",
    "                yield paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf = cudf.DataFrame(list(papers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:15:05.648232Z",
     "iopub.status.busy": "2022-09-21T14:15:05.647929Z",
     "iopub.status.idle": "2022-09-21T14:15:08.987166Z",
     "shell.execute_reply": "2022-09-21T14:15:08.986572Z",
     "shell.execute_reply.started": "2022-09-21T14:15:05.648210Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Pro Tip: Pickle the dataframe\n",
    "# This might save you time in the future so you don't have to do all of that again\n",
    "with open('cdf.pkl', 'wb') as f:\n",
    "    pickle.dump(cdf, f)\n",
    "    \n",
    "# Load pickle\n",
    "# with open('cdf.pkl', 'rb') as f:\n",
    "#     cdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:15:08.988256Z",
     "iopub.status.busy": "2022-09-21T14:15:08.987954Z",
     "iopub.status.idle": "2022-09-21T14:15:08.996862Z",
     "shell.execute_reply": "2022-09-21T14:15:08.996429Z",
     "shell.execute_reply.started": "2022-09-21T14:15:08.988235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713361"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still going to downsample here\n",
    "len(cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask to parallelize things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:20:11.049343Z",
     "iopub.status.busy": "2022-09-21T14:20:11.048952Z",
     "iopub.status.idle": "2022-09-21T14:20:11.067010Z",
     "shell.execute_reply": "2022-09-21T14:20:11.066474Z",
     "shell.execute_reply.started": "2022-09-21T14:20:11.049315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert our CuDF to a Dask-CuDF\n",
    "ddf = dask_cudf.from_cudf(cdf, npartitions=n_workers).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:20:58.661514Z",
     "iopub.status.busy": "2022-09-21T14:20:58.661112Z",
     "iopub.status.idle": "2022-09-21T14:20:58.667541Z",
     "shell.execute_reply": "2022-09-21T14:20:58.667041Z",
     "shell.execute_reply.started": "2022-09-21T14:20:58.661486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import get_worker\n",
    "import numpy as np\n",
    "\n",
    "def embed_partition(df: dask_cudf.DataFrame):\n",
    "    \"\"\"\n",
    "    Create embeddings on single partition of DF (one dask worker)\n",
    "    \"\"\"\n",
    "    worker = get_worker()\n",
    "    if hasattr(worker, \"model\"):\n",
    "        model = worker.model\n",
    "    else:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        worker.model = model\n",
    "\n",
    "    print(\"embedding input\", flush=True)\n",
    "        \n",
    "    # embed the input      \n",
    "    vectors = model.encode(\n",
    "        sentences = df.input.values_host,\n",
    "        normalize_embeddings = True,\n",
    "        show_progress_bar = True\n",
    "    )\n",
    "    \n",
    "    # Convert to cudf series and return\n",
    "    df['vector'] = cudf.Series(vectors.tolist(), index=df.index)\n",
    "    return df[['id', 'vector']]\n",
    "\n",
    "def clear_workers():\n",
    "    \"\"\"\n",
    "    Deletes model attribute, freeing up memory on the Dask workers\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import gc\n",
    "\n",
    "    worker = get_worker()\n",
    "    if hasattr(worker, \"model\"):\n",
    "        del worker.model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:21:04.195975Z",
     "iopub.status.busy": "2022-09-21T14:21:04.195593Z",
     "iopub.status.idle": "2022-09-21T15:08:27.395949Z",
     "shell.execute_reply": "2022-09-21T15:08:27.395365Z",
     "shell.execute_reply.started": "2022-09-21T14:21:04.195948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 340 ms, total: 2.36 s\n",
      "Wall time: 47min 23s\n"
     ]
    }
   ],
   "source": [
    "output_df = ddf[[\"id\", \"input\"]].map_partitions(\n",
    "    func = embed_partition,\n",
    "    meta = {\n",
    "      \"id\": object,\n",
    "      \"vector\": cudf.ListDtype('float32')\n",
    "    }\n",
    ")\n",
    "# Gather results\n",
    "output_df = output_df.persist()\n",
    "%time _ = wait(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:08:27.397267Z",
     "iopub.status.busy": "2022-09-21T15:08:27.396968Z",
     "iopub.status.idle": "2022-09-21T15:08:27.457947Z",
     "shell.execute_reply": "2022-09-21T15:08:27.457416Z",
     "shell.execute_reply.started": "2022-09-21T15:08:27.397245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713361"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output\n",
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:08:27.458967Z",
     "iopub.status.busy": "2022-09-21T15:08:27.458680Z",
     "iopub.status.idle": "2022-09-21T15:08:27.590351Z",
     "shell.execute_reply": "2022-09-21T15:08:27.589850Z",
     "shell.execute_reply.started": "2022-09-21T15:08:27.458946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output\n",
    "output_df.vector.isna().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:22:07.993850Z",
     "iopub.status.busy": "2022-09-21T15:22:07.993435Z",
     "iopub.status.idle": "2022-09-21T15:22:08.014028Z",
     "shell.execute_reply": "2022-09-21T15:22:08.013483Z",
     "shell.execute_reply.started": "2022-09-21T15:22:07.993813Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge and then take a sample of all ML papers AND papers older than 2015\n",
    "full_ddf = ddf.merge(output_df)\n",
    "full_ddf = full_ddf[(full_ddf.categories.str.contains(ML_CATEGORY)) | (full_ddf.year >= 2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:22:16.150352Z",
     "iopub.status.busy": "2022-09-21T15:22:16.149958Z",
     "iopub.status.idle": "2022-09-21T15:22:21.430931Z",
     "shell.execute_reply": "2022-09-21T15:22:21.430422Z",
     "shell.execute_reply.started": "2022-09-21T15:22:16.150324Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309164"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:23:15.822187Z",
     "iopub.status.busy": "2022-09-21T15:23:15.821778Z",
     "iopub.status.idle": "2022-09-21T15:23:41.899493Z",
     "shell.execute_reply": "2022-09-21T15:23:41.898969Z",
     "shell.execute_reply.started": "2022-09-21T15:23:15.822160Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store as pickled pandas df\n",
    "\n",
    "with open('arxiv_embeddings_300000.pkl', 'wb') as f:\n",
    "    pickle.dump(full_ddf.compute().to_pandas(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanup dask worker RAM\n",
    "#client.run(clear_workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
